{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**What is Tensor**"
      ],
      "metadata": {
        "id": "-iVlMwHnKQZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyzsqGxnKLQl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A tensor is essentially an array, which can support many mathematical operations, and will form a building block for our neural networks\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Begin by importing PyTorch.\n",
        "Create a tensor from the Python list temperatures.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "\n",
        "temperatures = [[72, 75, 78], [70, 73, 76]]\n",
        "\n",
        "# Create a tensor from temperatures\n",
        "temp_tensor = torch.tensor(temperatures)"
      ],
      "metadata": {
        "id": "cNL7jidgKrhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Check the shape of the temperatures tensor.\n",
        "Check the type of the temperatures tensor.\n",
        "Add the temperatures and adjustment tensors.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "temperatures = torch.tensor([[72, 75, 78], [70, 73, 76]])\n",
        "adjustment = torch.tensor([[2, 2, 2], [2, 2, 2]])\n",
        "\n",
        "# Check the shape of the temperatures tensor\n",
        "temp_shape = temperatures.shape\n",
        "print(\"Shape of temperatures:\", temp_shape)\n",
        "\n",
        "# Check the type of the temperatures tensor\n",
        "temp_type = temperatures.dtype\n",
        "print(\"Data type of temperatures:\", temp_type)\n",
        "\n",
        "# Adjust the temperatures by adding the adjustment tensor\n",
        "corrected_temperatures = temperatures + adjustment\n",
        "\n",
        "print(\"Corrected temperatures:\", corrected_temperatures)"
      ],
      "metadata": {
        "id": "Gt_tU8r_MgYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Neural Network**"
      ],
      "metadata": {
        "id": "7ucDcZb5Ms1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "we pass input_tensor to a special kind of layer called a linear layer. A linear layer takes an input tensor, applies a linear function to it, and returns an output.\n",
        "nn.Linear() takes two arguments: in_features, which is the number of features in our input (three), and out_features,\n",
        "specifying the desired size of the output tensor (in this case two).\n",
        "\n",
        "Networks with only linear layers are called fully connected\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "## Create input_tensor with three features\n",
        "input_tensor = torch.tensor(\n",
        "    [[0.3471, 0.4547, -0.2356]]\n",
        "    )\n",
        "\n",
        "# Define linear layer\n",
        "linear_layer = nn.Linear(\n",
        "      in_features=3,\n",
        "      out_features=2\n",
        ")\n",
        "\n",
        "#### Consider the linear_layer object we created. Each linear layer has a set of weights and biases associated with it\n",
        "\n",
        "# Pass input through linear layer\n",
        "output = linear_layer(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVRbo4l0Mnrd",
        "outputId": "bfe1d453-508e-4572-a18d-05524a63fe70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4092,  0.2538]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What if we wanted to stack multiple layers?**"
      ],
      "metadata": {
        "id": "d0iUUlKBOt2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Create network with three linear layers\n",
        "model = nn.Sequential(\n",
        "      nn.Linear(10, 18),\n",
        "      nn.Linear(18, 20),\n",
        "      nn.Linear(20, 5)\n",
        ")"
      ],
      "metadata": {
        "id": "6aXXGNYNN1sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Implement a small neural network containing two linear layers. The first layer takes an eight-dimensional input, and the last layer outputs a one-dimensional tensor.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Create a neural network of two linear layers that takes a tensor of dimensions\n",
        "as input, representing 8 features, and outputs a tensor of dimensions 1.\n",
        "\n",
        "\n",
        "Use any output dimension for the first layer you want.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
        "\n",
        "# Implement a small neural network with two linear layers\n",
        "model = nn.Sequential(\n",
        "                    nn.Linear(8 , 3),\n",
        "                    nn.Linear(3 , 1)\n",
        "                     )\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "8r0OkFFZPQZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Functions**"
      ],
      "metadata": {
        "id": "-Mox8niXPtgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Sigmoid Function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "input_tensor = torch.tensor([[6.0]])\n",
        "sigmoid = nn.Sigmoid()\n",
        "output = sigmoid(input_tensor)"
      ],
      "metadata": {
        "id": "o9Zgn316QFZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "The sigmoid is commonly used as the last step in a neural network when performing binary classification.\n",
        "\n",
        "\n",
        "A sigmoid as the last step in a network of only linear layers is equivalent to a logistic regression using traditional machine learning!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "model = nn.Sequential(\n",
        "      nn.Linear(6, 4), # First linear layer\n",
        "      nn.Linear(4, 1), # Second linear layer\n",
        "      nn.Sigmoid() # Sigmoid activation function\n",
        ")"
      ],
      "metadata": {
        "id": "RqkG72HaQuby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Multiclass Classification\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "In PyTorch, we use nn.Softmax(). dim equals minus one indicates that softmax is applied to input_tensor's last dimension.\n",
        "Similar to sigmoid, softmax can be the last layer in nn.Sequential.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "as nn\n",
        "# Create an input tensor\n",
        "input_tensor = torch.tensor(\n",
        "[[4.3, 6.1, 2.3]])\n",
        "# Apply softmax along the last dimension\n",
        "probabilities = nn.Softmax(dim=-1)\n",
        "output_tensor = probabilities(input_tensor)\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "id": "bVsKJYgWS75T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create a sigmoid function and apply it on input_tensor to generate a probability for a binary classification task.\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.tensor([[0.8]])\n",
        "\n",
        "# Create a sigmoid function and apply it on input_tensor\n",
        "sigmoid = nn.Sigmoid()\n",
        "probability = sigmoid(input_tensor)\n",
        "print(probability)\n"
      ],
      "metadata": {
        "id": "dHF1eFtZTLL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create a softmax function and apply it on input_tensor to generate a probability for a multiclass classification task.\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
        "\n",
        "# Create a softmax function and apply it on input_tensor\n",
        "softmax = nn.Softmax(dim = -1)\n",
        "probabilities = softmax(input_tensor)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "5pOotnhATqeB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}